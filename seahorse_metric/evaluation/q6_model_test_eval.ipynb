{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f763f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:21:59.616144Z",
     "start_time": "2025-05-29T16:21:59.613013Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tools\n",
    "from const import (\n",
    "    LEN,\n",
    "    QUESTION,\n",
    "    DATASET_NAME,\n",
    "    FORMAT,\n",
    "    ZERO_TOKEN,\n",
    "    ONE_TOKEN,\n",
    "    MAX_INPUT_LENGTH,\n",
    "    SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dde1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = [\"ru\"]\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "PER_DEVICE_EVAL_BATCH_SIZE = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2467c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d80fab90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['gem_id', 'lang', 'text', 'summary', 'model', 'comprehensible', 'repetition', 'grammar', 'attribution', 'main_ideas', 'conciseness'],\n",
       "        num_rows: 4111\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['gem_id', 'lang', 'text', 'summary', 'model', 'comprehensible', 'repetition', 'grammar', 'attribution', 'main_ideas', 'conciseness'],\n",
       "        num_rows: 597\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['gem_id', 'lang', 'text', 'summary', 'model', 'comprehensible', 'repetition', 'grammar', 'attribution', 'main_ideas', 'conciseness'],\n",
       "        num_rows: 1233\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seahorse = load_dataset(DATASET_NAME)\n",
    "\n",
    "def filter_data(example): \n",
    "    if(example[QUESTION] == 0.5):\n",
    "        return False\n",
    "\n",
    "    example[QUESTION] = int(example[QUESTION])\n",
    "    return example['lang'] in LANGUAGES and len(example['summary']) > LEN and len([token for token in word_tokenize(example['summary'], language='russian') if token.isalpha()]) >= 20\n",
    "\n",
    "seahorse_filtered = seahorse.filter(filter_data)\n",
    "seahorse_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff37bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"seahorse_metric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dbdf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "zero_token_id = tokenizer(ZERO_TOKEN).input_ids[0]\n",
    "one_token_id = tokenizer(ONE_TOKEN).input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17a8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_long_examples(example):\n",
    "        inputs = FORMAT.format(example['text'], example['summary'])\n",
    "        tokenized = tokenizer(inputs, truncation=False)\n",
    "        return len(tokenized['input_ids']) <= MAX_INPUT_LENGTH\n",
    "\n",
    "validation_data_filtered_by_len = seahorse_filtered['validation'].filter(filter_long_examples, num_proc=4)\n",
    "test_data_filtered_by_len = seahorse_filtered['test'].filter(filter_long_examples, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9269c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [FORMAT.format(article, summary)\n",
    "            for article, summary in zip(examples['text'], examples['summary'])]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=False, # Defer padding to DataCollator\n",
    "    )\n",
    "    model_inputs[\"labels\"] = [[i] for i in examples[QUESTION]]\n",
    "    return model_inputs\n",
    "\n",
    "validation_tokenized = validation_data_filtered_by_len.map(preprocess_function, batched=True, num_proc=4, remove_columns=validation_data_filtered_by_len.column_names)\n",
    "test_tokenized = test_data_filtered_by_len.map(preprocess_function, batched=True, num_proc=4, remove_columns=test_data_filtered_by_len.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfab3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(validation_tokenized, batch_size=PER_DEVICE_EVAL_BATCH_SIZE, collate_fn=data_collator, shuffle=False)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_tokenized, batch_size=PER_DEVICE_EVAL_BATCH_SIZE, collate_fn=data_collator, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea55fb",
   "metadata": {},
   "source": [
    "# Vlidation Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d719fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbd8933e54644b2a4189e134ef7e33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating and collecting logits:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793368830b3d4b28afa496535f074f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best threshold:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal threshold found: 0.4400 (max F1 = 0.7265)\n"
     ]
    }
   ],
   "source": [
    "val_logits_target, val_labels_binary = tools.get_logits_and_labels(\n",
    "    model, val_data_loader, zero_token_id, one_token_id, DEVICE\n",
    ")\n",
    "optimal_threshold = tools.find_best_threshold(val_logits_target, val_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae3f08a",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1484db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a569eb7c83a4c2e8f0ddbcc272844a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating and collecting logits:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'pearson_corr': 0.4587684140690601,\n",
       " 'roc_auc': 0.7805154307213431,\n",
       " 'accuracy': 0.710804224207961,\n",
       " 'f1': 0.7156035358651394,\n",
       " 'mean_confidence_overall': 0.7909254,\n",
       " 'mean_confidence_correct': 0.82086253,\n",
       " 'mean_confidence_incorrect': 0.71734405,\n",
       " 'ece': 0.08814920775726995,\n",
       " 'mce': 0.1410748458677723}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_logits_target, test_labels_binary = tools.get_logits_and_labels(\n",
    "    model, test_data_loader, zero_token_id, one_token_id, DEVICE\n",
    ")\n",
    "final_results = tools.calculate_final_metrics(\n",
    "    test_logits_target, test_labels_binary, optimal_threshold\n",
    ")\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0735de0c",
   "metadata": {},
   "source": [
    "# Results After Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bbfa21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "val_probs = torch.sigmoid(torch.tensor(val_logits_target[:, 1] - val_logits_target[:, 0])).numpy()\n",
    "test_probs = torch.sigmoid(torch.tensor(test_logits_target[:, 1] - test_logits_target[:, 0])).numpy()\n",
    "\n",
    "isotonic_calibrator = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "isotonic_calibrator.fit(val_probs, val_labels_binary)\n",
    "calibrated_probabilities = isotonic_calibrator.transform(test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4135ed6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ae500c3c1f4421b3491f1d287980b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best threshold:   0%|          | 0/101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal threshold found: 0.3700 (max F1 = 0.7298)\n"
     ]
    }
   ],
   "source": [
    "val_calibrated_probabilities = isotonic_calibrator.transform(val_probs)\n",
    "optimal_calibrated_threshold = tools.find_best_threshold_from_probabilities(val_calibrated_probabilities, val_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a8d1724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin 3 is empty.\n",
      "Bin 6 is empty.\n",
      "Bin 8 is empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pearson_corr': 0.4587684140690601,\n",
       " 'roc_auc': 0.7805154307213431,\n",
       " 'accuracy': 0.7124289195775793,\n",
       " 'f1': 0.7172072325970649,\n",
       " 'mean_confidence_overall': 0.7259493,\n",
       " 'mean_confidence_correct': 0.751194,\n",
       " 'mean_confidence_incorrect': 0.6634081,\n",
       " 'ece': 0.04807778492049412,\n",
       " 'mce': 0.1524728826574377}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_final_results = tools.calculate_calibrated_metrics(\n",
    "             test_logits_target,\n",
    "             test_labels_binary,\n",
    "             optimal_calibrated_threshold,\n",
    "             calibrated_probabilities\n",
    "    )\n",
    "calibrated_final_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

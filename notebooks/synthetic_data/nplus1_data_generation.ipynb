{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "b06c3df7875279a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\n",
    "from common import (\n",
    "    FRED_T5_MODEL_NAME,\n",
    "    INPUT_TOKEN_LIMIT_FRED_T5,\n",
    "    TASK_PROMPT,\n",
    "    MIN_TEXT_TOKENS_FOR_SUMMARIZATION,\n",
    "    GEMINI_API_KEY,\n",
    "    GEMINI_MODEL_NAME_PRIMARY\n",
    ")\n",
    "import common\n",
    "from datasets import load_dataset\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "HF_DATASET_NAME = \"cointegrated/taiga_stripped_rest\"\n",
    "HF_DATASET_SPLIT = \"NPlus1\"\n",
    "OUTPUT_JSONL_FILE = \"nplus1_generated_summaries.jsonl\"\n",
    "PROCESSED_INDICES_FILE = \"nplus1_processed_indices.txt\"\n",
    "FINAL_HF_DATASET_PATH = \"nplus1_gemini\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(FRED_T5_MODEL_NAME)"
   ],
   "id": "9efd1d544c94fd53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:16:18.356221Z",
     "start_time": "2025-05-22T11:16:18.350132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens_in_task_prompt_fred_t5 = len(tokenizer(TASK_PROMPT, add_special_tokens=False)['input_ids'])\n",
    "NUM_SPECIAL_TOKENS_FOR_FRED_T5_INPUT = 1\n",
    "MAX_TEXT_TOKENS_FOR_FRED_T5_COMPATIBLE_INPUT = INPUT_TOKEN_LIMIT_FRED_T5 - \\\n",
    "                                               tokens_in_task_prompt_fred_t5 - \\\n",
    "                                               NUM_SPECIAL_TOKENS_FOR_FRED_T5_INPUT"
   ],
   "id": "19e3366d6723f3d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полный лимит входа FRED-T5: 1024\n",
      "Токены в TASK_PROMPT_FRED_T5_FOR_TRAINING ('<LM> Сократи текст: '): 6\n",
      "Специальные токены FRED-T5 для входа: 1\n",
      "Макс. токены для чистого текста (чтобы уместиться в FRED-T5 с его промптом): 1017\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:16:24.815741Z",
     "start_time": "2025-05-22T11:16:18.523271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_dataset = load_dataset(HF_DATASET_NAME, split=HF_DATASET_SPLIT)\n",
    "print(f\"Loaded '{HF_DATASET_SPLIT}' split with {len(raw_dataset)} examples.\")"
   ],
   "id": "950f5676a14ed908",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'NPlus1' split with 7000 examples.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:16:35.707147Z",
     "start_time": "2025-05-22T11:16:24.838101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prepared_dataset_for_gemini = common.preprocess_and_filter_dataset_with_exact_deduplication(\n",
    "    raw_dataset,\n",
    "    tokenizer,\n",
    "    MAX_TEXT_TOKENS_FOR_FRED_T5_COMPATIBLE_INPUT,\n",
    "    MIN_TEXT_TOKENS_FOR_SUMMARIZATION\n",
    ")"
   ],
   "id": "dataset_loading_and_preparation",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing. Initial size: 7000\n",
      "Targeting max text tokens for processing: 1017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cleaning, Truncating, and Exact Deduplicating:   0%|          | 0/7000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30643d682cb24127af139a097290c9ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing. Exact duplicates found and skipped: 1\n",
      "Filtered dataset size after exact deduplication: 6855\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:16:35.717862Z",
     "start_time": "2025-05-22T11:16:35.715727Z"
    }
   },
   "cell_type": "code",
   "source": "prepared_dataset_for_gemini",
   "id": "efd047b487104954",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'processed_text', 'processed_text_tokens'],\n",
       "    num_rows: 6855\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:44:09.592433Z",
     "start_time": "2025-05-22T15:44:09.588925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model_gemini = genai.GenerativeModel(GEMINI_MODEL_NAME_PRIMARY)"
   ],
   "id": "gemini_model_initialization",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully configured Gemini with model: gemini-2.0-flash\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:25:39.915200Z",
     "start_time": "2025-05-22T15:44:29.916466Z"
    }
   },
   "cell_type": "code",
   "source": "common.generate_summaries_resumable_full_stats(prepared_dataset_for_gemini, model_gemini, tokenizer, PROCESSED_INDICES_FILE, OUTPUT_JSONL_FILE)",
   "id": "gemini_summarization_process",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6490 already processed indices.\n",
      "Attempting to process 365 items in this run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generating Summaries & Full Stats:   0%|          | 0/365 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3229c02c2944c7f8b6ffa5dc60e25fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generation Finished for this Run ---\n",
      "Processed: 365, Total Time: 829.36s, Avg/Item: 2.27s\n",
      "\n",
      "Source Stats:\n",
      "  Chars: Avg=2546.44, Min=575, Max=5350\n",
      "  Words: Avg=376.08, Min=86, Max=818\n",
      "  Tokens: Avg=516.77, Min=111, Max=998\n",
      "\n",
      "All Summary Candidates (1095 non-empty):\n",
      "  Chars:\n",
      "    Avg=815.61, Min=339, Max=1274\n",
      "    Comp.: Avg=0.354, Min=0.137, Max=0.861\n",
      "    25% Quantile: Abs=714.00, Comp.=0.280\n",
      "    50% Quantile: Abs=824.00, Comp.=0.335\n",
      "    75% Quantile: Abs=919.00, Comp.=0.406\n",
      "  Words:\n",
      "    Avg=120.20, Min=51, Max=184\n",
      "    Comp.: Avg=0.356, Min=0.132, Max=0.891\n",
      "    25% Quantile: Abs=104.00, Comp.=0.280\n",
      "    50% Quantile: Abs=120.00, Comp.=0.338\n",
      "    75% Quantile: Abs=137.00, Comp.=0.411\n",
      "  Tokens:\n",
      "    Avg=172.87, Min=71, Max=274\n",
      "    Comp.: Avg=0.370, Min=0.135, Max=0.842\n",
      "    25% Quantile: Abs=148.00, Comp.=0.293\n",
      "    50% Quantile: Abs=173.00, Comp.=0.352\n",
      "    75% Quantile: Abs=198.00, Comp.=0.429\n",
      "\n",
      "Items with no summaries: []\n",
      "Success distribution:\n",
      "  3 summaries: 365 items\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:27:09.311106Z",
     "start_time": "2025-05-22T16:27:09.306634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed_indices = []\n",
    "if os.path.exists(PROCESSED_INDICES_FILE): \n",
    "    with open(PROCESSED_INDICES_FILE) as f:\n",
    "        processed_indices = [int(line.strip()) for line in f if line.strip()]\n",
    "len(processed_indices) == len(set(processed_indices)), len(processed_indices)"
   ],
   "id": "e20e0a63e4a1576e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 6855)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T16:27:45.390477Z",
     "start_time": "2025-05-22T16:27:45.007171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_dataset = common.create_final_huggingface_dataset_from_jsonl(OUTPUT_JSONL_FILE, FINAL_HF_DATASET_PATH)\n",
    "final_dataset"
   ],
   "id": "final_dataset_assembly_and_save",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Hugging Face dataset with 6855 examples from JSONL.\n",
      "Saving Hugging Face dataset to nplus1_gemini...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6855 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e194d1ea93cd44219e16c5c768b307e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face dataset saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'text', 'summaries'],\n",
       "    num_rows: 6855\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
